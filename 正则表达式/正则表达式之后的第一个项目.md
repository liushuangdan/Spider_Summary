
正则表达式之后的第一个项目
===

----

百度贴吧内的图片下载：

需求是：找一个贴吧，下载这个贴吧下的所有的图片。（仅包括正文中的）


思路：
1. 需求的分析，要找的是一个百度贴吧，下载的是正文的图片，并且是所有的。
2. 获取图片所在的URL，看分页，看规律。
3. 这时候我们可以爬下来一个页面并且验证成功
4. 这个贴吧的所有页面的汇总页，观察，找规律
5. 然后再爬取汇总页的全部图片试试
6. 最后汇总页也有分页，再进行分页的处理。

```python
from urllib import request, parse
import re

import signal

is_sigint_up = False

def sigint_handler(signum, frame):
    global is_sigint_up
    is_sigint_up = True
    print('catched interrupt signal!')

signal.signal(signal.SIGINT, sigint_handler)

start_url = 'https://tieba.baidu.com/f?kw='+ parse.quote('搞笑图片') + '&ie=utf-8&pn='
max_pn = 63900

def parse_detailed_url(url, pn):
    html_str = ''
    try:
        response = request.urlopen(url)
        html_str = response.read().decode('utf-8')
    except:
        print("url opend failed, url = %s" % url)
        return False
    pattern = re.compile(r'<img class="BDE_Image".*src="(.*?)"')

    image_list = pattern.findall(html_str)

    for image in image_list:
        if is_sigint_up:
            break;
        image = parse.urljoin('http://tieba.baidu.com', image)
        print("downloading.... %s " % image)
        fname = image.split('/')[-1]
        fname = 'image/' + fname
        try:
            request.urlretrieve(image, fname)
        except:
            print("downloading failed %s " % image)

    pattern = re.compile(r'class="l_reply_num".*回复贴，共.*(\d+?)', re.S)
    page_num = pattern.findall(html_str)
    print('The total num is %s' % page_num)
    if int(page_num[0]) <= pn + 1:
        return False
    return True

def parse_whole_post(url):
    loops = True
    loops_count = 0
    while loops:
        if is_sigint_up:
            break;
        html_url = url + "?pn=" + str(loops_count)
        loops_count += 1
        print('start to parse detailed html url = %s' % html_url)
        loops = parse_detailed_url(html_url, pn)


def url_index_parse(url):
    response = request.urlopen(url)
    html_str = response.read().decode('utf-8')
    pattern = re.compile(r'<div class="threadlist_title pull_left j_th_tit.*? href="(.*?)"', re.S)

    url_list = pattern.findall(html_str)

    for url in url_list:
        if is_sigint_up:
            break;
        url = parse.urljoin('https://tieba.baidu.com', url)
        print('start to parse whole post url = %s' % url)
        parse_whole_post(url)

for pn in range(0, max_pn+1,50):
    if is_sigint_up:
        break;
    url = start_url + str(pn)
    print('start to parse pn = %s' % url)
    url_index_parse(url)
```












